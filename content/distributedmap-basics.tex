\chapter{Distributed Map Basics}

In this chapter, you'll learn how to use one of the most versatile data structures in Hazelcast; the com.hazelcast.core.IMap. The IMap implements the java.util.concurrent.ConcurrentMap interface, and therefor it also implement the java.util.Map interface and is designed to be used in a distributed environment.

Internally Hazelcast divides the map in partitions (by default 271) and distributes the partitions evenly among the members in the cluster. Based on the key of the map entry the partition is determined, so each key belongs to a single partition. 

Scaling up the cluster is simple; just add more members. When new members are found in the cluster, the oldest member decides which partitions need to be moved to the new members. It tries to choose the partitions that contain the least amount of data to prevent copying a lot of data. Hazelcast doesn't do any runtime rebalancing of partitions bases for example on partition size or usage currently.

To scale down also is simple; just shutdown the HazelcastInstance. And the partitions will automatically be reassigned to other members. Of course a hard kill of the JVM is possible, but then you run a risk of loosing something.

[TODO: Give some idea about capacity in production.. number of entries... total size.

The commercial offering of Hazelcast includes Elastic Memory where the map entries are not stored in the Java Heap. One of the reasons to use it is that gc times are drastically reduced. There is demonstration on youtube: http://www.youtube.com/watch?v=TOhbhKqJpvw  where 4 Terabyte of data from 1 billion entries is stored on 100 Amazon EC2 instances. Leading to 1.3 million of operations/second.

[TODO: ConcurrentMap operations never throw java.util.ConcurrentModificationException. Add somewhere.]

\begin{enumerate}
\item Reading/Writing
\item Custom Keys
\item Query API
\item Indices
\item Data Locality
\item High Availability
\item Concurrency Control
\item Gotcha's
\end{enumerate}

\section{Reading/Writing}
The HazelcastMap implements the java.util.Map interface, so putting retrieving key/values is very simple since you can use familiar methods like get/put etc.

I'll show this behavior using an example where 1 member fills a map with some entries:
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import java.util.Map;
public class FillMapMember {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        Map<String, String> map = hzInstance.getMap("map");
        map.put("1", "Tokyo");
        map.put("2", "Paris");
        map.put("3", "New York");
    }
}
\end{lstlisting}
As you can see the Map can be retrieved using the hzInstance.getMap(mapName) and after the map is retrieved, some entries are stored in that map. 

And reading out the entries we can do like this:
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import java.util.Map;
public class PrintAllMember {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        Map<String, String> map = hzInstance.getMap("map");
        for(Map.Entry<String,String> entry : map.entrySet()){
            System.out.println(entry.getKey()+" "+entry.getValue());
        }
    }
}
\end{lstlisting}
When we first start the FillMapMember and then PrintAllMember, we'll get output like this:
\begin{lstlisting}
1 Tokyo
2 Paris
3 New York
\end{lstlisting}

\section{Hashcode and equals}
In most cases, when you work with a Hazelcast map, you probably will make use of some basic type like a  Long, Integer or String as key. But in some cases you will need to create custom keys. But to do it correctly in Hazelcast, you need to understand how this mechanism in Hazelcast works. 

When you store a key/value in a Hazelcast map, the actual objects are not stored in the map, because an object can't move from one JVM to another. Instead the keys and values are serialized to byte arrays and these will be stored in the Hazelcast map. To correctly make use of hash/equals in Hazelcast you need to know the following:
\begin{enumerate}
\item For keys the hash/equals is determined based on the content of the byte array, so equal keys need to result in equal byte arrays.
\item For values the hash/equals of the object is used, and not the hash/equals of the byte array content. So the hash/equals for value work as normal.
\end{enumerate}
As you can see the difference is subtile, but it is crucial to understand.

Below is an example of a key implementation that is valid if you use it as key in a normal map implementation like the HashMap, but stops working when it is used as a key in a Hazelcast map:
\begin{lstlisting}[language=java]
public final class BrokenKey implements Serializable {
    private final String significant;
    private final String insignificant;
    public BrokenKey(String significant, String insignificant) {
        this.significant = significant;
        this.insignificant = insignificant;
    }
    public boolean equals(Object o) {
        if (this == o) return true;
        if (!(o instanceof BrokenKey)) return false;
        BrokenKey that = (BrokenKey) o;
        return that.significant.equals(this.significant);
    }
    public int hashCode() {
       return significant.hashCode();
   }
}
\end{lstlisting}
This BrokenKey has 2 fields; the significant field is used in the hash/equals implementation and the insignificant field is not. If we would make 2 keys:
\begin{lstlisting}
BrokenKey key1 = new BrokenKey("a","b");
BrokenKey key2 = new BrokenKey("a","c");
\end{lstlisting} 
Then 'key1.equals(key2)' and 'key1.hashCode()==key2.hashCode()'. So it is a valid key for a normal map implementation. But because the byte array of key1 (which will contains 'a' and 'b') is different than the byte array of key2 (which will contain 'a' and 'c'), the hash code and equals will be different. And therefor this key is broken. Of course the problem can be solved by preventing the field to be part of the byte array, e.g. by making the field transient.

[TODO:Note that the distributed Set and List stores its entries as the keys in a distributed Map. So the notes above apply to the objects you store in Set and List.]

\section{Distributed Queries}
Imagine that we have a Hazelcast map containing persons where the key is some id and the value is Person object and we want to retrieve all persons with a given name. We could create the following very naive implementation:
\begin{lstlisting}[language=java]
   public Set<Person> getWithNameNaive(String name){
        Set<Person> result = new HashSet<Person>();
        for(Person person: personMap.values()){
            if(person.name.equals(name))
                result.add(person);
        }
        return result;
    }
\end{lstlisting}
This is what you probably would write if the map would be an ordinary map. But when the map is distributed map, there are some performance and scalability problems with this approach:
\begin{enumerate}
\item It is not parallelizable. One member will iterate over all persons instead of spreading the load over multiple members. Because the search isn't parallelizable, the system can't scale; you can add more members to the cluster to increase performance.
\item It is inefficient because all persons need to be pulled over the line before being deserialized into the memory of the executing member. So there is a huge amount of network traffic because all data go over the line.
\end{enumerate}

Luckily Hazelcast solves these problems by supporting predicates that are executed on top of a fork/join mechanism:
\begin{enumerate}
\item when the predicate is requested to be evaluated by the caller, it is forked to each member in the cluster
\item each member will filter all map entries that are stored locally using the predicate. Before a predicate evaluates an map entry, the key/value of that entry are deserialized and passed to the predicate. 
\item the caller joins on the completion by all members and merges the results into a single set
\end{enumerate}
The fork/join approach is highly scalable because it parallelizable. By adding additional cluster members, the number of partitions per member is reduced and therefor the time a member needs to iterate over all its data, is reduced as well. Also the local filtering is parallelizable because a pool of 'partition threads' will evaluate segments of elements concurrently. And last but not least, the amount of network traffic is reduced drastically, since only filtered data are send instead of all data.

Hazelcast provides 2 api's for distributed queries:
\begin{enumerate}
\item Criteria API
\item Distributed SQL Query
\end{enumerate}

\subsection*{Criteria API}
To implement the Person search using the criteria API, it could be as simple as this:
\begin{lstlisting}[language=java]
    public Set<Person> getWithName(String name) {
        Expression getNameExpression = Predicates.get("name");
        Predicate predicate = Predicates.equal(getNameExpression, name);
        return (Set<Person>) personMap.values(predicate);
    }
\end{lstlisting}
First we need to get the name of the Person. This is done by the 'get' expression. Then we need to create an equal predicate that has as input the expression that gets the name and the other input is the name we are looking for. After we have created the predicate, we apply it to the personMap by calling the 'IMap.values(Predicate)' method which takes care of sending it to all members in the cluster, evaluating it, and merging the result. The Predicate is not limited to values only. It can also apply be applied to the keySet, the entrySet and the localKeySet of the IMap. 

\subsubsection*{Get expression}
In the previous example we already saw the get expression in action where it gets the name of the person object. When it is evaluated, it first tries to lookup an accessor method, so in case of 'name', the accessor methods it will try are 'isName()' and 'getName()'. If one found, it is called and the evaluation has completed. Of course an accessor method doesn't need to return a field, it could also be a synthetic accessor where some value is determined on the fly. If no accessor is found, a field with the given name is looked up. If that exists, it is returned and otherwise a RuntimeException is thrown. Hazelcast doesn't care about the accessibility of a field or an accessor method, so you are not forced to make them public.

In some cases you need to traverse over an object structure, e.g. we want the street of the address the person lives at. With the get expression this can be done like this: 'address.street'. This expression is evaluated from left to right and there is no limit on the number of steps involved. Also accessor methods can be used here. Another thing important to know is how the get expression deals with null, especially with object traversal. As soon null is found, null is returned instead of a NullPointerException being thrown. So if address would be null, the evaluation of the get expression 'address.street' will return null.

If you find the get expression too limited, you can create your own expression by extending the com.hazelcast.query.Expression interface:
\begin{lstlisting}[language=java]
public interface Expression<T> extends Serializable {
    T getValue(Object obj);
}
\end{lstlisting}

\subsubsection*{And, Or and Not predicates}
Predicates can also be joined using the 'and' and 'or' predicate:
\begin{lstlisting}[language=java]
import static com.hazelcast.query.Predicates.*;
   ...
   public Set<Person> getWithNameAndAge(String name, int age) {
      Predicate namePredicate = equal(get("name"), name);
      Predicate agePredicate = equal(get("age"), age);
      Predicate predicate = and(namePredicate, agePredicate);
      return (Set<Person>) personMap.values(predicate);
   }
   public Set<Person> getWithNameOrAge(String name, int age) {
       Predicate namePredicate = equal(get("name"), name);
       Predicate agePredicate = equal(get("age"), age);
       Predicate Person = or(namePredicate, agePredicate);
       return (Set<Person>) personMap.values(predicate);
   }
\end{lstlisting}
And of course we can't forget the 'not' predicate:
\begin{lstlisting}[language=java]
    public Set<Person> getNotWithName(String name) {
        Predicate namePredicate = equal(get("name"), name);
        Predicate predicate = not(namePredicate);
        return (Set<Person>) personMap.values(predicate);
    }
\end{lstlisting}

\subsubsection*{Other predicates}
In the Predicates class you can find a whole collections of useful predicates:
\begin{enumerate}
\item notEqual: checks if the result of an expression is not equal to a certain value.
\item instanceOf: checks if the result of an expression has a certain type
\item like: checks if the result of an expression matches some string pattern. \% (percentage sign) is placeholder for many characters, \_ (underscore) is placeholder for only one character.
\item greaterThan: checks if the result of an expression is greater than a certain value.
\item greaterEqual: checks if the result of an expression is greater or equal than a certain value.
\item lessThan: checks if the result of an expression is less than a certain value
\item lessEqual: checks if the result of an expression is than than or equal to a certain value.
\item between: checks if the result of an expression is between 2 values (this is inclusive).
\item in: checks if the result of an expression is an element of a certain collection.
\item isNot: checks if the result of an expression is false.
\item regular expression: checks if the result of an expression matches some regular expression. Although there is no static convenience function for it on Predicates, the Predicates.RegexPredicate is publicly available.
\end{enumerate}
If the predicates provided by Hazelcast are not enough, you can always write your own predicate by implementing the Predicate interface:
\begin{lstlisting}[language=java]
public interface Predicate<K, V> extends Serializable {
    boolean apply(MapEntry<K, V> mapEntry);
}
\end{lstlisting}
The MapEntry not only contains the key/value, but also contains all kinds of metadata like the time it was created/expires/last-accessed etc. 

\subsubsection*{PredicateBuilder}
The syntax we used so far to create Predicates is clear but can be simplified by making use of the PredicateBuilder. It provides a fluent interface that can make building predicates simpler. But underwater the same functionality is being used. Here is an example where a predicate is build that selects all persons with a certain name and age using this PredicateBuilder:
\begin{lstlisting}[language=java]
    public Set<Person> getWithNameAndAgeSimplified(String name, int age) {
        EntryObject e = new PredicateBuilder().getEntryObject();
        Predicate predicate = e.get("name").equal(name).and(e.get("age").equal(age));
        return (Set<Person>) personMap.values(predicate);
    }
\end{lstlisting}
As you can see, it can simplify things, especially if you have complex predicates. But it is a matter of taste which approach you prefer.

\subsection*{Distributed SQL Query}
In the previous section the Criteria API was explained where expression/predicate objects are manually created. The pain can be reduced a bit by making use of the PredicateBuilder, but it still isn't perfect. That is why a DSL implementation was added: the Distributed SQL Query where a SQL like language is used. But underwater the the Criteria API is used. 

The 'get with name' function we already implemented using the Criteria API, can be implementing using the Distributed SQL Query like this:
\begin{lstlisting}
public Set<Person> getWithName(String name){
    Predicate predicate = new SqlPredicate(String.format("name = %s",name));
    return (Set<Person>) personMap.values(predicate);
}
\end{lstlisting}
As you can see, the SqlPredicate is a Predicate itself and therefor can be combined with the Criteria API. The language itself isn't case sensitive.

\subsubsection*{AND/OR}
<expression> AND <expression> AND <expression>...
\begin{lstlisting}
man AND age>30
man=false OR age = 45 OR name = 'Joe'
man AND (age >20 OR age < 30)
\end{lstlisting}

\subsubsection*{=, !=, <, <=, >, >=}
<expression> = value
\begin{lstlisting}
age <= 30
name ="Joe"
age != 30
\end{lstlisting}

\subsubsection*{BETWEEN}
<attribute> [NOT] BETWEEN <value1> AND <value2>
\begin{lstlisting}
age BETWEEN 20 AND 33
age NOT BETWEEN 30 AND 40
\end{lstlisting}

\subsection{LIKE}
<attribute> [NOT] LIKE 'expression'
\% (percentage sign) is placeholder for many characters, \_ (underscore) is placeholder for only one character.
\begin{lstlisting}
name LIKE 'Jo%' (true for 'Joe', 'Josh', 'Joseph' etc.)
name LIKE 'Jo_' (true for 'Joe'; false for 'Josh')
name NOT LIKE 'Jo_' (true for 'Josh'; false for 'Joe')
name LIKE 'J_s%' (true for 'Josh', 'Joseph'; false 'John', 'Joe')
\end{lstlisting}

\subsubsection{IN}
<attribute> [NOT] IN (val1, val2, ...)
\begin{lstlisting}
age IN (20, 30, 40)
age NOT IN (60, 70)
\end{lstlisting}

\section{Indices}
To speed up queries, just like in databases, the Hazelcast map implementation supports indexes. Using an index prevents from iterating over all values (in database terms this is called a full table scan), but directly jump to the interesting ones. There are 2 types of indexes:
\begin{enumerate}
\item Ordered: e.g. a numeric field where you want to do searches like bigger than.
\item Unordered: e.g. a name field.
\end{enumerate}
In the previous chapter we talked a Person class which has a name, age etc. The speed up searching on these fields, we can place an unordered index on name and ordered index on age. 

To retrieve the index field of an Object, first an accessor method will be tried and if that doesn't exist, direct field access will be used. With the index accessor method you are not limited to returning a field, you could have a synthetic accessor method where some value is calculated on the fly. The index field also supports object traversal, so you could create a index on the street of the address of a person using 'address.street' as index. There is no limitation on the depth of the traversal.Hazelcast doesn't care about the accessibility of the index field or an index accessor method, so you are not forced to make them public. An index field also is allowed to return null.

The indexes on the personMap can be configured through the hazelcast configuration file. 
\begin{lstlisting}[language=xml]
<hazelcast>
   ...
   <map name="persons">
      <indexes>
         <index ordered="false">name</index>
         <index ordered="true">age</index>
      </indexes>
   </map>
</hazelcast>
\end{lstlisting}
It also is possible to call the 'IMap.addIndex(String name,boolean ordered)' method directly, but adding the index should be done before an item is placed in the map. Sometimes by design adding an index to map may be impossible before any value is added. For example if a map has MapLoader that loads entries during map creation, then adding indexes to map becomes meaningless. Another disadvantage of doing it in code is that it can become hard to figure out if a field has an index, because it could be spread over the code.

The performance impact of using one or more indices depends on a lot of factors; among them are the size of the  map, the chance of finding the element with a full table scan etc. Also adding one or more indices make mutations to the map more expensive since the index needs to be updated as well. Therefor you need to test in a production like environment, number and type of machines, size/quality of the dataset, which configuration is best for you. In the source code you can 2 very rudimentary benchmark frameworks, one for updating and one for searching, you can play with and can extend. 

\section{MultiMap}
In some cases you need to attach multiple values for a single key. Luckily Hazelcast provides out of the box functionality for that in the form of a MultiMap. The MultiMap doesn't implement the java.util.Map interface since the signatures of the method are different. The MultiMap does have support for most of the functionality provided by the IMap (so locking, listeners etc). But it doesn't support indexing.

The reason why the MultiMap exists, apart from being easy to use is efficiency. If you would use the hazelcast map with an ordinary collection as value, then you need to deserialize the whole collection for every operation you do on that collection (e.g. adding a single element). With the MultiMap this isn't needed, so it is a lot more efficient.

To demonstrate the MultiMap where are going to create 2 member; in one member dummy data is created and in the other member it is read and written to the console.
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
public class PutMember {
    public static void main(String[] args){
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        MultiMap<String,String> map = hzInstance.getMultiMap("map");
        
        map.put("Peter","England");
        map.put("Peter","Holland");
        map.put("Talip","Turkey");
    }
}
\end{lstlisting}

\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import java.util.Collection;
public class PrintMember {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        MultiMap<String,String> map = hzInstance.getMultiMap("map");
        for(String key: map.keySet()){
            Collection<String> values = map.get(key);
            System.out.printf("%s -> %s\n",key,values);
        }
    }
}
\end{lstlisting}
It is important to realize that map.get(key) returns a copy of the values at some moment in time. Changes to this collection will result in an a UnsupportedOperationException. So if you want to change the values, you need to do it through the map.remove methods.

Removing items; you can remove items from the MultiMap. This is using the equals operator of the value. If the collection for a specific key is empty, this collection will not automatically be removed, so it can be that you need to clean up the MultiMap so that no empty value collections remains.

The value collection is set based, so no duplicates and there is no ordering.Null value is not allowed (npe). But the MultiMap can also be configured to be list based: MultiMapConfig.setValueCollectionType(ValueCollectionType.LIST). 

One thing worth knowing; if a value collection with K is stored on member1 because K is owned by that member1, and member2 does a map.get(K), then the whole collection will transported from member1 to member 2. So if that value collection is big, it could lead to performance problems. A solution would be to send the whole operation to member1, so send the logic to the data instead of the data to the logic.

\section{Data locality}
In some cases you want data that logically belongs to each other, is stored on the same partition to have locality of reference (an important feature for performance). This prevents going over the network, since the data is stored in the same partition.

Imagine that you have a Customer:
\begin{lstlisting}[language=java]
import java.io.Serializable;
public class Customer implements Serializable {
    public final long id;
    public Customer(long id) {
        this.id = id;
    }
}
\end{lstlisting}
And imagine that each customer can have orders:
\begin{lstlisting}[language=java]
import java.io.Serializable;
public final class Order implements Serializable {
    public final long orderId;
    public final long customerId;
    public final long articleId;
    public Order(long orderId, long customerId, long articleId) {
        this.orderId = orderId;
        this.customerId = customerId;
        this.articleId = articleId;
    }
}
\end{lstlisting}
And imagine that customers and orders are stored in a map like this:
\begin{lstlisting}[language=java]
    Customer customer = new Customer(100);
    customerMap.put(customer.id, customer);

    Order order = new Order(200,customer.id,300)
	orderMap.put(order.id, order)
\end{lstlisting}
The problem with this approach is that it is very likely that the customer is going to be stored in a different partition than its orders because the customer is partitioned based on the customer id, and the orders are partitioned on the order id.

This can be solved by making use of the PartitionAware interface. If a key for the IMap implements this interface, instead of using the hashcode of the object to determine the correct partition, the PartitionAware.getPartitionKey() method will be called and the result of this method will be used to determine the right partition. 

In our case we introduce an intermediate object: the OrderKey that implements this PartitionAware interface and returns the customerId as the partitionKey:
\begin{lstlisting}[language=java]
import com.hazelcast.core.PartitionAware;
import java.io.Serializable;
public final class OrderKey implements PartitionAware, Serializable {
    public final long orderId;
    public final long customerId;
    public OrderKey(long orderId, long customerId) {
        this.orderId = orderId;
        this.customerId = customerId;
    }
    public Object getPartitionKey() {
        return customerId;
    }
}
\end{lstlisting}
We don't need to add an equals/hashcode since the equals/hashcode based on the byte content of the OrderKey is used.

And we can integrate it in our code and verify that the partition of the customer is the same as the partition of the order:
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import com.hazelcast.partition.*;
import java.util.Map;
public class Main {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        Map<Long, Customer> customerMap = hzInstance.getMap("customers");
        Map<OrderKey, Order> orderMap = hzInstance.getMap("orders");

        long customerId = 100;
        long orderId = 200;
        long articleId = 300;

        Customer customer = new Customer(customerId);
        customerMap.put(customer.id, customer);

        OrderKey orderKey = new OrderKey(orderId,customer.id);
        Order order = new Order(orderKey.orderId,customer.id,articleId);
        orderMap.put(orderKey, order);

        PartitionService pService = hzInstance.getPartitionService();
        Partition cPartition = pService.getPartition(customerId);
        Partition kPartition = pService.getPartition(new OrderKey(orderId, customerId));
        Partition oPartition = pService.getPartition(orderId);

        System.out.printf("Partition for customer: %s\n", cPartition.getPartitionId());
        System.out.printf("Partition for order with OrderKey: %s\n", kPartition.getPartitionId());
        System.out.printf("Partition for order without OrderKey: %s\n", oPartition.getPartitionId());
    }
}
\end{lstlisting}
The Output would look something like this:
\begin{lstlisting}
Partition for customer: 124
Partition for order with OrderKey: 124
Partition for order without OrderKey: 175
\end{lstlisting}
As you can see, the partition where the Customer is stored, is the same as the partition where the Order of that same customer is stored. 

Being able to control what data is placed in the same partition, is a very powerful feature and needs to be taking into consideration from the beginning and therefor is a very important architectural concern. Once this is done correctly, it will be a lot easier to write a high performance and scalable system. And the technique of partitioning data in a single partition, can be combined with sending functionality to the data instead of the data to the functionality. So if you need to do some operation, send that operation to the right partition. For more information see "chapter: Executor and Routing" and "chapter: Distributed Services and routing".

\section{High availability}
By default all data that is written will automatically be written synchronously to another JVM. This prevents data from getting lost if a JVM crashes, because it will be available on another JVM. By customizing the Hazelcast configuration file:
\begin{verbatim}
<hazelcast> 
<map name="customers"> 
<backup-count>1</backup-count>
 	</map> 
</hazelcast>
\end{verbatim}

This configuration specifies that the customers map should have a single backup. This is also the default, so if you are fine with that, you do not need to specify it. But if you 

This configuration 
Consistency
todo explain default
Explain asynchronous

\section{Persistance}
In the previous section we talked about backups that protect against member failure, so if one member goes down, another member takes over. But it does not protect you against cluster failure, e.g. when a datacenter goes down. Another problem we have not talked about is that we are keeping all the entries in the map in memory, and this is not always desirable. Luckily Hazelcast provides a solution for these problems by allowing to load and store data externally, e.g. in a database. This can be done using:
\begin{enumerate}
\item com.hazelcast.core.MapLoader: useful for reading entries from an external datasource, but changes don't need to be written back.
\item com.hazelcast.core.MapStore: useful for reading and writing map entries from and to an external datasource. The MapStore interface extends the MapLoader interface.
\end{enumerate}
One word of caution: the MapLoader/MapStore should NOT call Map/Queue/MultiMap/List/Set operations, otherwise you might run into deadlocks.

In the example below you can see an extremely basic HSQLDB implementation of the MapStore where we load/store a simple Person object with a name field:
\begin{lstlisting}[language=java]
import com.hazelcast.core.MapStore;
import java.sql.*;
import java.util.*;
import static java.lang.String.format;
public class PersonMapStore implements MapStore<Long, Person> {
    private final Connection con;
    public PersonMapStore() {
        try {
            con = DriverManager.getConnection("jdbc:hsqldb:mydatabase", "SA", "");
            con.createStatement().executeUpdate(
                    "create table if not exists person (id bigint, name varchar(45))");
        } catch (SQLException e) {throw new RuntimeException(e);}
    }
    public void delete(Long key) {
        try {
            con.createStatement().executeUpdate(
                    format("delete from person where id = %s", key));
        } catch (SQLException e) {throw new RuntimeException(e);}
    }
    public void store(Long key, Person value) {
        try {
            con.createStatement().executeUpdate(
                    format("insert into person values(%s,'%s')", key, value.name));
        } catch (SQLException e) {throw new RuntimeException(e);}
    }
    public void storeAll(Map<Long, Person> map) {
        for (Map.Entry<Long, Person> entry : map.entrySet())
            store(entry.getKey(), entry.getValue());
    }
    public void deleteAll(Collection<Long> keys) {
       for(Long key: keys) delete(key);
    }
    public Person load(Long key) {
        try {
            ResultSet resultSet = con.createStatement().executeQuery(
                    format("select name from person where id =%s", key));
            try {
                if (!resultSet.next())return null;
                String name = resultSet.getString(1);
                return new Person(name);
            } finally {
                resultSet.close();
            }
        } catch (SQLException e) {throw new RuntimeException(e);}
    }
    public Map<Long, Person> loadAll(Collection<Long> keys) {
        Map<Long, Person> result = new HashMap<Long, Person>();
        for (Long key : keys) result.put(key, load(key));
        return result;
    }
    public Set<Long> loadAllKeys() {
         return null;
    }
}
\end{lstlisting}
As you can see the implementation is quite simple, but certainly can be improved, e.g. transactions, prevention against sql injection etc. 

To connect the PersonMapStore to the persons map, we can configure it like this in the Hazelcast configuration file:
\begin{lstlisting}[language=xml]
<hazelcast>
    <map name="persons">
        <map-store enabled="true">
           <class-name>PersonMapStore</class-name>
         </map-store>
    </map>
</hazelcast>
\end{lstlisting}

\subsubsection{Pre-Populating the map}
With the MapLoader it is possible to pre-populate the Map so that when it is created, the important entries are loaded in memory. This can be done by letting the 'loadAllKeys' method return the Set of all 'hot' keys that need to be loaded for the partitions owned by the member. This also makes parallel loading possible, since each member can load its own keys.  If the 'loadAll' method return null, as we did in the example, then the map will not be pre-populated. Also important to know is that Map is created lazily by Hazelcast, so only when one of the members calls the 'HazelcastInstance.getMap(name)' the map is actually created and the MapLoader called. If your application requires that Map up front without really needing the content, you could wrap the map in a lazy proxy that calls the getMap method only when really needed.

I common mistake made is that the 'loadAllKeys' returns all keys in the database table. This could be problematic since you would pull the complete table in memory, but another important problem is that if each member returns the all keys, each member will load the complete table from the database. So if a you have 1.000.000 records in the database, and 10 members, then the total number of records loaded is 10.000.000 instead of 1.000.000. Of course the Map.size will still be 1.000.000. That is why a member should only load the records it owns, e.g. by adding the 

[todo: do not return all keys in the database; since each member is going to do the same. Is there any form of protection against this? Because when new members are added, they will load the map and therefor the load-all-keys method is called. So how can you do this once only?]
[todo: how to figure out in which partition you are]
[todo: how to figure out which data to load from the database]

You need to be aware of that the map only knows about map entries that are in memory, only when a get is done for an explicit key, then the map entry is loaded from the MapStore. This behavior is called a read through. So if the loadAll would return a subset of the keys in the database, then e.g. the Map.size() will show only the size of this subset, not the record count in the database. And the same goes for queries; these will only be executed on the entries in memory, not on the records in the database.

To make sure that you only keep hot entries in memory, you can configure the 'time-to-live-seconds' property on the Map. When a Map entry isn't used and the time to live expires, it will automatically be removed from the map without calling the MapStore.delete. 

\subsubsection*{Write Through vs Write Behind}
Although the MapStore makes durability possible, it also comes at a cost: every time that a change is made in the map, a write through to the your persistence mechanism happens. Write through operations increase latency since databases cause latency (e.g. disk access). In Hazelcast it is possible to use a write behind instead of a write through. When a change happens, the change is synchronously written to the backup partition (if that is configured), but the change to the database is done asynchronously. Enabling write behind can be done by configuring the 'write-delay-seconds' in the 'map-store' configuration section. It defaults to 0, which means a write through. A value higher than 0 indicates a write behind. Using write behind is not completely without danger, it could happen that the cluster fails before the write to the database has completed. In that case information could be lost.

\subsubsection*{MapLoaderLifecycleSupport}
In some cases your MapLoader needs to be notified of lifecycle events. This can be done by letting the MapLoader implementation implement the com.hazelcast.core.MapLoaderLifecycleSupport interface. This signals to Hazelcast that the implementation is interested in:
\begin{enumerate}
\item init: useful if you want to initialize resources like opening database connections. One of the parameters the init method receives is a Properties object. This is useful if you want to pass properties from the outside to the MapLoader implementation. If you make use of the xml configuration, in the map-store xml configuration you can specify the properties that need to be passed to the init method.
\item destroy: useful if need to cleanup resources like closing database connections.
\end{enumerate}

\section{Concurrency Control}
The Hazelcast map itself is threadsafe just like the ConcurrentHashMap or the Collections.synchronizedMap, but in some cased your thread safety requirements are bigger than what hazelcast provides out of the box. Luckily Hazelcast provides multiple concurrency control solutions;  it can either be pessimistic using locks or optimistic using compare and swap operations. Todo: what about transactions?

Take a look at the following example; if run by multiple members in parallel the total amount would be 
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import java.io.Serializable;
public class RacyUpdateMember {
    public static void main(String[] args) throws Exception {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        IMap<String, Value> map = hzInstance.getMap("map");
        String key = "1";
        map.put(key, new Value());
        System.out.println("Starting");
        for (int k = 0; k < 1000; k++) {
            if(k%100 == 0)System.out.println("At: "+k);
            Value value = map.get(key);
            Thread.sleep(10);
            value.field++;
            map.put(key, value);
        }

        System.out.println("Finished! Result = " + map.get(key).field);
    }
    static class Value implements Serializable {
        public int field;
    }
}
\end{lstlisting}

\subsection{Pessimistic Locking}
The classic way to solve the race problem is to use a lock. In Hazelcast there are various ways to lock, but for this example we'll use the locking functionality provided by the map using the map.lock/map.unlock methods.

Todo: are these reentrant?
todo: are these fair?
also the regular locking rules apply, don't lock too long, don't lock too much.

\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import java.io.Serializable;
public class PessimisticUpdateMember {
    public static void main(String[] args) throws Exception {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        IMap<String, Value> map = hzInstance.getMap("map");
        String key = "1";
        map.put(key, new Value());
        System.out.println("Starting");
        for (int k = 0; k < 1000; k++) {
            map.lock(key);
            try {
                Value value = map.get(key);
                Thread.sleep(10);
                value.field++;
                map.put(key, value);
            } finally {
                map.unlock(key);
            }
        }
        System.out.println("Finished! Result = " + map.get(key).field);
    }
    static class Value implements Serializable {
        public int field;
    }
}
\end{lstlisting}
Another way to lock is to acquire some predictable Lock object from Hazelcast. You could give every value its own lock, but you could also create a stripe of locks. Although it potentially can increase contention, it will reduce space.

todo: when a key is locked, it still is possible to do a read, but not to do a write.

\subsection{Optimistic Locking}
TODO: Does optimistic rely on a lock or is truly using cas?

It is important to implement equals on the value, because this is used to determine of 2 objects are equal. With the ConcurrentHashMap it is based on object reference. On the keys the byte-array equals is used, but on the replace(key,oldValue,newValue) the equals is used. If you fail to forget it, your code will not work!

\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import java.io.Serializable;
//This code is broken on purpose.
public class OptimisticMember {
    public static void main(String[] args) throws Exception {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance(null);
        IMap<String, Value> map = hzInstance.getMap("map");
        String key = "1";
        map.put(key, new Value());
        System.out.println("Starting");
        for (int k = 0; k < 1000; k++) {
            if(k%10==0) System.out.println("At: "+k);
            for (; ; ) {
                Value oldValue = map.get(key);
                Value newValue = new Value(oldValue);
                //   Thread.sleep(10);
                newValue.field++;
                if(map.replace(key, oldValue, newValue))
                    break;
            }
        }
        System.out.println("Finished! Result = " + map.get(key).field);
    }
    static class Value implements Serializable {
        public int field;
        public Value(){}
        public Value(Value that) {
            this.field = that.field;
        }
        public boolean equals(Object o){
            if(o == this)return true;
            if(!(o instanceof Value))return false;
            Value that  = (Value)o;
            return that.field == this.field;
        }
    }
}
\end{lstlisting}
Aba problem; it can be that the following thing happens. And explain how it can be solved by adding a version; although all the other fields will be equal, the version field will prevent objects from being seen as equal.

\subsection{Pessimistic vs Optimistic}
TODO: When to choose one, when to choose the other. Normally optimistic performs better if there is not that much contention. What is the reason to do so in Hazelcast? Is it better performing?

\section{Gotcha's}
When Map.entrySet(), Map.keySet() or Map.values() is called, a snapshot of the current state of the map is returned. Changes that are made in the map, so not reflect into changes these maps. Also when changes are made on these collections, an UnsupportedOperationException is thrown.

Changes made on keys/values after they have been persisted, will not reflect in changes in the map. This is because not the key/value object themselves are stored, but their serialized version. So the following idiom is broken:
\begin{lstlisting}[language=java]
Employee e = employeeMap.get("123");
e.fire();
\end{lstlisting}
If you want the changes in e to be published, you need to write e back to the map.

TODO: What about cache where serialization for local object is 'skipped?

\section{What is next}
In this chapter a lot of the basic operations on the Distributed Map were explained. In the next chapter we'll cover more advanced features.
