\chapter{Distributed Collections}

Hazelcast provides a set of collections that implement interfaces from the java collection 
framework and make it easy to integration distributed collections without too many code changes.
This chapter will example distributed collections like:
\begin{enumerate}
\item BlockingQueue
\item Set
\item List
\end{enumerate}
The distributed map functionality provided by Hazelcast is so extensive that 2 separate chapters
have been dedicated to it. 

One of the cool thing about distributed collections in Hazelcast is that when a node fails that
a manages (a part of) a distributed collection, another node will immediately take over without
any elements in the collection getting lost

\section{Distributed Queue}

A blocking queue is one of the working horses for concurrent system because it 
allows producers and consumers of messages to work in different speeds. The Hazelcast BlockingQueue
implementation not only allows threads from the same machine to interact with that queue, but
since the queue is distributed it also allows different jvm's to interact with it.

As an example we have a BlockingQueue that stores Integers. We have an java process that produces
integers; the Producer. And we also have a Java process that consumes Integers; the Consumer. When the
Producer is finished, it will post -1 on the queue to indicate to the consumers that they can stop. Such
a special control message also is called a poison pill.

The Producer:
\begin{lstlisting}[language=java]
import com.hazelcast.core.Hazelcast;
import java.util.concurrent.BlockingQueue;
public class ProducerMain {
    public static void main(String[] args) throws Exception {
        BlockingQueue<Integer> queue = Hazelcast.getQueue("producerConsumerQueue");
        for (int k = 1; k < 1000; k++) {
            Thread.sleep(1000);  
            queue.put(k);
            System.out.println("Producing: " + k);
        }
        queue.put(-1);
        System.out.println("Producer Finished!");
    }
}
\end{lstlisting}

The Consumer:
\begin{lstlisting}[language=java]
import com.hazelcast.core.Hazelcast;
import java.util.concurrent.BlockingQueue;
public class ConsumerMain {
    public static void main(String[] args) throws Exception {
        BlockingQueue<Integer> queue = Hazelcast.getQueue("producerConsumerQueue");
        while (true){
            Thread.sleep(1000);  
            int item = queue.take();
            System.out.println("Consumed: " + item);
            if(item == -1){
                queue.put(-1);
                break;
            }           
        }
        System.out.println("Consumer Finished!");
    }
}
\end{lstlisting}
If you take a closer look at consuming the message, we see that when the consumer receives the poison pill,
that before it ends the loop, it put the poison pill back on the queue. This is done to make sure that all
consumer will receive the poison pill, and not only the one that received it first.

When you begin with starting a single producer, you will see the following output:
\begin{verbatim}
Produced 1
Produced 2
Produced 3
....
\end{verbatim}

When you start a single consumer, you will see the following output:
\begin{verbatim}
Consumed 1
Consumed 2
Consumed 3
....
\end{verbatim}

To improve scalability, you can create as many producers and consumers as you want; just launch 
more of them. For example if we start another consumer, we'll see that on consumer takes care of
on half of the elements and the other consumer takes care of the other half.

Consumer 1:
\begin{verbatim}
Consumed 20
Consumed 22
Consumed 24
....
\end{verbatim}

Consumer 2:
\begin{verbatim}
Consumed 21
Consumed 23
Consumed 25
....
\end{verbatim}

And when you kill one of the consumers, the remaining consumer will process all elements again:

Consumer 1:
\begin{verbatim}
Consumed 40  
Consumed 42 
Consumed 44 
Consumed 45
Consumed 46
....
\end{verbatim}

One thing to watch out for however, eventually the queue will become the bottleneck for similar reasons a normal 
BlockingQueue implementation will; and that is contention. One way of solving this problem is to introduce 
a stripe (a list) of BlockingQueues but ordering is no longer guaranteed that way.

\emph{Important}: Realize that although the queue itself preserves ordering of the messages (so the messages
are taken from the queue in the order they were put on the queue), if there are multiple consumers 
on the same queue, the order in which items get processed is not guaranteed. This is because processing
of messages taken happens in parallel and queue will not provide any ordering guarantees on messages
after they are taken from the queue.

\subsection{BlockingQueue Capacity}

In the previous example we created a basic producer consumer implementation with a shared
Hazelcast BlockingQueue. Because the production of messages is separated from the consumption
of messages, the speed of production of messages is not influenced by the speed of consumption.

If producing of messages goes quicker than the consumption the queue will increase in size. If 
there is no bound on the capacity of the queue, machines can run out of memory. With the traditional 
BlockingQueue implementations like the LinkedBlockingQueue a capacity can be set. With the maximum 
capacity is reached, placement of new items either fail, or block depending on the operation used
to place an item on the queue. This prevents the queue from growing beyond a healthy capacity.

Hazelcast also provided control in the capacity, but instead of having a fixed capacity, Hazelcast
provides a scalable capacity by setting a queue capacity per jvm. So if the capacity per jvm is 1000
and there are 5 jvm's, the total capacity is 5000. So capacity depends on the size of the cluster; 
add more machines and the capacity of the queue will grow. Remove machines from the cluster and 
the capacity of the queue will shrink 

TODO: (what will happen when the queue is 'full' and machine is removed?) 

To give our producerConsumerQueue a capacity, we add the following to our hazelcast.xml file.
\begin{verbatim}
<hazelcast>
    <queue name="producerConsumerQueue">
        <max-size-per-jvm>10</max-size-per-jvm>
    </queue>
</hazelcast>
\end{verbatim}

When we start a single producer, we'll see that 10 items are produced and than the producer
blocks. When we start a single consumer, we'll immediately see that the producer will continue
since the total capacity is now 20 (2 jvm's and each jvm'1 has 10 for max-size-per-jvm). 

\subsection{Time to live}
TODO: Is there also a distributed dequeue?

\section{Distributed List}

After the distributed queue, we have the list. As you most likely know a list is a 
datastructure where the ordering of elements matters. 

An example of Distributed List in Hazelcast.

\begin{lstlisting}[language=java]
public class ListExample{
    public static void main(String[] args){
	
    }
}
\end{lstlisting}

TODO: read mostly?

\section{Distributed Set}

A Set is a collection where every element only occurs ones. In Hazelcast a Set has 

TODO: Good explanation of equals/hash

\begin{lstlisting}[language=java]
public class ListExample{
    public static void main(String[] args){
	
    }
}
\end{lstlisting}


\section{Collection Item Listeners}

When in Hazelcast a distributed List,Set or Queue is retrieved, these collection implement
the ICollection interface. The nice thing is that Hazelcast enriches the existing collections api
with item listeners. The following example shows an itemListener that listens to all changes made
in a queue, but to listen to changes in a Set or List are similar.

\begin{lstlisting}[language=java]
import org.hazelcast.core.*;	
public class ItemListenerMain{
    public static void main(String[] args){
        IQueue<String> queue = Hazelcast.getQueue("queue");
        queue.addItemListener(
            new ItemListener<String>{
                public void itemAdded(String item){
                    System.out.println("item added: "+item);
                }
                public void itemRemoved(String item){ 
                    System.out.println("item removed:"+item);
                }
            }
        );
    }
}
\end{lstlisting}

And to see that the ItemListeners really are working, start up the ItemListenerMain
first, and after that run the following ItemChangerMain:

\begin{lstlisting}[language=java]
import org.hazelcast.core.*;	
public class ItemChangerMain{
    public static void main(String[] args){
        IQueue<String> queue = Hazelcast.getQueue("queue");
        queue.put("foo");
        queue.put("bar");
        queue.take();
        queue.take();
    }
}
\end{lstlisting}

The output of the ItemListenerMain will show the following:
\begin{verbatim}
item added: foo
item added: bar
item removed: bar
item removed: foo
\end{verbatim}

ItemListeners are useful if you need to react upon changes in collections. But realize that listeners 
are executed asynchronously, so it could be that at the time your listener runs, that the collection 
has changed again.

TODO: Will item listeners be executed in parallel?

\section{ITopic}

\section{What is next?}
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi libero sem,
interdum eget varius vel, faucibus placerat purus. Sed vulputate diam sit amet
risus dapibus dignissim. Praesent lobortis eleifend augue. Cum sociis natoque
penatibus et magnis dis parturient montes, nascetur ridiculus mus. Morbi libero
turpis, viverra ac vulputate a, faucibus vel quam. Quisque interdum congue
lacus, in tempus nisl tincidunt at. Curabitur sed eros eu enim vehicula
fermentum quis nec justo. Vestibulum rutrum laoreet est, eget condimentum justo
feugiat at. Cras ac sem ac magna ornare tempor non nec nisl. Maecenas feugiat
fringilla nisl, vitae ullamcorper ante posuere a. Sed mollis lacinia interdum.
Vivamus vel urna metus. Nulla eget tellus sem. Praesent volutpat suscipit nulla,
nec dictum arcu iaculis id. Duis pharetra vestibulum sapien, quis pulvinar odio
pharetra id. Cras at erat velit, vel tincidunt elit. Curabitur vehicula leo eu
odio vulputate ac consequat nulla ultricies. Maecenas venenatis condimentum
urna ut ultrices. Aliquam blandit fermentum eros, ac lacinia sem scelerisque
at. Nullam vitae nisi at erat posuere cursus a non velit.
