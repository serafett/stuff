\chapter{Distributed Collections}
Hazelcast provides a set of collections that implement interfaces from the Java collection framework and therefor make it easy to integration distributed collections in your system without too many code changes. A distributed collection can not only be called concurrently from the same JVM, it also can be called concurrently by different JVM's. Another advantage is that the distributed collections provide high availability, so if a member hosting the collection fail, another member will take over.

\section{IQueue}
A BlockingQueue is one of the work horses for concurrent system because it allows producers and consumers of messages, which can be POJO's, to work different speeds. The Hazelcast com.hazelcast.core.IQueue, which extends the java.util.concurrent.BlockingQueue, not only allows threads from the same JVM to interact with that queue, but since the queue is distributed, it also allows different JVM's to interact it. So you can add items in one JVM and remove them in another.

As an example we'll create a producer/consumer implementation that is connected by a distributed queue. The producer is going to put a total of 100 Integers on the queue with a rate of 1 message/second.
\begin{lstlisting}[language=java]
public class ProducerMember {
    public static void main(String[] args) throws Exception {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        IQueue<Integer> queue = hzInstance.getQueue("queue");
        for (int k = 1; k < 100; k++) {
            queue.put(k);
            System.out.println("Producing: " + k);
            Thread.sleep(1000);}
        queue.put(-1);
        System.out.println("Producer Finished!");
    }
}
\end{lstlisting}
To make sure that the consumers are going to terminate when the producer is finished, the producer will put a -1 on the queue to indicate that it is ready. When a consumer reads this message, also called a poison pill, it terminates. 

The consumer will take the message from the queue, print it and waits 5 seconds before consuming the next message and stops when it receives the poison pill:
\begin{lstlisting}[language=java]
public class ConsumerMember {
    public static void main(String[] args) throws Exception {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        IQueue<Integer> queue = hzInstance.getQueue("queue");
        while (true){
            int item = queue.take();
            System.out.println("Consumed: " + item);
            if(item == -1){
                queue.put(-1);
                break;}     
            Thread.sleep(5000);}
        System.out.println("Consumer Finished!");
    }
}
\end{lstlisting}
If you take a closer look at the consumer, you see that when the consumer receives the poison pill, it puts the poison pill back on the queue before it ends the loop. This is done to make sure that all consumer will also receive the poison pill, and not only the one that received it first.

When you start a single producer, you will see the following output:
\begin{lstlisting}
Produced 1
Produced 2
....
\end{lstlisting}
When you start a single consumer, you will see the following output:
\begin{lstlisting}
Consumed 1
Consumed 2
....
\end{lstlisting}
As you can see, the items produced on the queue by the producer are being consumed from that same queue by the consumer. 

Because messages are produced 5 times faster than they are consumed, with a single member the queue will keep growing. To improve throughput, you can start more consumers. If we start another one, we'll see each consumer takes care of half the messages. Consumer 1:
\begin{lstlisting}
Consumed 20
Consumed 22
....
\end{lstlisting}
Consumer 2:
\begin{lstlisting}
Consumed 21
Consumed 23
....
\end{lstlisting}
When you kill one of the consumers, the remaining consumer will process all elements again:
\begin{lstlisting}
Consumed 40  
Consumed 42 
....
\end{lstlisting}
One thing to take care of that if there are many producers/consumers interacting with the queue, is that the queue eventually will become a bottleneck and this is caused by contention. One way of solving this problem is to introduce a stripe (essentially a list) of BlockingQueues. But if you do, the ordering of messages send to different queues will not be guaranteed anymore. In a lot of cases a strict ordering isn't required and a stripe can be a simple solution to improve scalability.

\emph{Important}: Realize that although the Hazelcast distributed queue preserves ordering of the messages (so the messages are taken from the queue in the same order they were put on the queue), if there are multiple consumers, the processing order is not guaranteed because the queue will not provide any ordering guarantees on messages after they are taken.

\subsection{Capacity}
In the previous example we showed a basic producer/consumer solution based on a distributed queue. Because the production of messages is separated from the consumption of messages, the speed of production is not influenced by the speed of consumption. If producing messages goes quicker than the consumption, then the queue will increase in size. If there is no bound on the capacity of the queue, then machines can run out of memory and you will get an OutOfMemoryError. 

With the traditional BlockingQueue implementations, like the LinkedBlockingQueue, a capacity can be set. When this is set and the maximum capacity is reached, placement of new items either fail or block, depending on type of the put operation. This prevents the queue from growing beyond a healthy capacity and the JVM from failing.

The Hazelcast queue also provided capacity control, but instead of having a fixed capacity for the whole cluster, Hazelcast provides a scalable capacity by setting the queue capacity per member using the queue property max-size. So if the capacity per member is 1000 and there are 5 members's, the total capacity is 5000. Therefor the capacity depends on the size of the cluster. To give our queue a capacity of 10 per member, we set the max-size:
\begin{lstlisting}
<network>
    <join><multicast enabled="true"/></join>
</network>
<queue name="queue">
    <max-size>10</max-size>
</queue>
\end{lstlisting}
When we start a single producer, we'll see that 10 items are produced and then the producer blocks. If we then start a single consumer, we'll immediately see that the producer will continue since the total capacity for the queue has doubled to 20 (2 JVM's times 10 items per JVM). 

But since the producer produces 5 times as fast as the consumer, the queue will reach its maximum capacity again quickly and it will block. We can can increase the capacity of the cluster by starting new consumers (both processing and the storage capacity increase) or just empty members (the storage capacity increases).

\subsection{Backups}
By default Hazelcast will make sure that there is one synchronous backup for the queue; so if the member containing partitions of that queue fails, the backups on another member will be used so no data is lost.

Backups can be controlled using the async-backup count and backup-count property. If you want increased high availability you could either increase the backup-count or the asynchronous backup count. If you want to have improved performance you could remove the synchronous backup and replace it with a asynchronous backup (so there is a small chance of failure) or use no backup at all.

\subsection{QueueStore}
In some cases you want have persistent queues; so their state should be made available in a durable storage mechanism like a database. In Hazelcast 2 the Queue was implemented on top of the Hazelcast Map, so in theory you could make the queue persistent by configuring the MapStore of the backing map. In Hazelcast 3, the Queue is not implemented on top of a map anymore and now exposes a MapStore directly.

[todo: example]

\section{IList}
A List is a collection where every element only occurs ones and where the order of the element doesn't matter. The Hazelcast com.hazelcast.core.IList implements the java.util.List. We'll demonstrate the IList by adding items to a list on one member and on another member we print the elements from that list:
\begin{lstlisting}[language=java]
public class WriteMember {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        IList<String> list = hzInstance.getList("list");
        list.add("Tokyo");
        list.add("Paris");
        list.add("New York");
        System.out.println("Putting finished!");
    }
}
public class ReadMember {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        IList<String> list = hzInstance.getList("list");
        for (String s : list) System.out.println(s);
        System.out.println("Reading finished!");
    }
}
\end{lstlisting}
If you first run the WriteMember and after it has completed start the ReadMember then the ReadMember will output the following:
\begin{lstlisting}
Tokyo
Paris
New York
Reading finished!
\end{lstlisting}
As you can see, the data written to the List by the WriteMember is visible in the ReadMember and you also can see that the order is maintained. The List interface has various methods like the sublist that returns collections. See [todo: reference 'weak consistency' iterators at end of chapter]

\section{ISet}
A Set is a collection where every element only occurs ones and where the order of the element doesn't matter. The Hazelcast com.hazelcast.core.ISet implements the java.util.Set. We'll demonstrate the set by adding items in a Set on one member, and on another member we are going to print all the elements from that Set:
\begin{lstlisting}[language=java]
public class WriteMember {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        ISet<String> set = hzInstance.getSet("set");
        set.add("Tokyo");
        set.add("Paris");
        set.add("New York");
        System.out.println("Putting finished");
    }
}
public class ReadMember {
    public static void main(String[] args) {
         HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
         ISet<String> set = hzInstance.getSet("set");
         for(String s: set) System.out.println(s);
         System.out.println("Reading finished!");
    }
}
\end{lstlisting}
If you first start the WriteMember and waiting for completion, you start the ReadMember; it will output the following:
\begin{lstlisting}
Paris
Tokyo
New York
Reading finished!	
\end{lstlisting}
As you can see, the data added by the WriteMember is visible in the ReadMember. As you also can see, the order is not maintained since order is not defined by the Set.

Just as with normal HashSet, the hash and equals of the object are used and not the equals/hash of the byte array version of that object. This is different behavior compared to the map; see [reference to equals/hash section in the map]

In Hazelcast the ISet (and same goes for the IList) is implemented as a collection within the MultiMap, where the id of the set is the key in the multimap and the value is the collection. This means that the ISet is not partitioned, so you can't scale beyond the capacity of a single machine and you can't control where data from a set is going to be stored. If you want to have a distributed set that behaves more like the distributed map one simple option is to implement a set based on a map, where the value can be some bogus value. It isn't possible to rely on the Map.keySet for returning  a usable distributed set since it will return a non distributed snapshot of the keys.

\section{Collection Item Listeners}
The IList, ISet and IQueue interfaces extend the com.hazelcast.core.ICollection interface. The nice thing is that Hazelcast enriches the existing collections api with the ability to listen to changes in the collections using the com.hazelcast.core.ItemListener. The ItemListener receives the ItemEvent which not only (potentially) contains the item, but also the member where the changed happened and the type of event (add or remove).

The following example shows an ItemListener that listens to all changes made in an IQueue:
\begin{lstlisting}[language=java]
public class ItemListenerMember {
    public static void main(String[] args) throws Exception {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        ICollection<String> queue = hzInstance.getQueue("queue");
        queue.addItemListener(new ItemListenerImpl<String>(), true);
        System.out.println("ItemListener started");
    }
    private static class ItemListenerImpl<E> implements ItemListener<E> {
        public void itemAdded(ItemEvent<E> itemEvent) {
            System.out.println("Item added:" + itemEvent.getItem());}
        public void itemRemoved(ItemEvent<E> itemEvent) {
            System.out.println("Item removed:" + itemEvent.getItem());
        }
    }
}
\end{lstlisting}
We registered the ItemListenerImpl with the addItemListener method using the value 'true'. This is done to make sure that our ItemListenerImpl will get the value that has been added/removed. The reason why this configuration option is available, is that in some cases you only want to be notified that a change happened, but you're not interested in the actual change and don't want to pay for sending the value over the line.

To see that the ItemListener really is working, we'll create a member that makes a change in the queue:
\begin{lstlisting}[language=java]
public class CollectionChangeMember{
    public static void main(String[] args) throws Exception {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        BlockingQueue<String> queue = hzInstance.getQueue("queue");
        queue.put("foo");
        queue.put("bar");
        queue.take();
        queue.take();
    }
}
\end{lstlisting}
First start up the ItemListenerMember and wait till it displays "ItemListener started". After that start the CollectionChangeMember and you will see the following output in the ItemListenerMember:
\begin{lstlisting}
item added:foo
item added:bar
item removed:foo
item removed:bar
\end{lstlisting}
ItemListeners are useful if you need to react upon changes in collections. But realize that listeners are executed asynchronously, so it could be that at the time your listener runs, that the collection has changed again. 

\emph{Ordering} All events are ordered, meaning, listeners will receive and process the events in the order they are actually occurred. TODO: Is the ordering only guaranteed within the member, or is there a cluster wide ordering?

\section{Gotcha's}

\emph{Iterator stability:} iterators on collections are weakly consistent; meaning that when a collection changes while creating the iterator, you could encounter duplicates or miss element. Changes on that iterator will not result in changes on the collection. An iterator doesn't need to reflect the actual state and will not throw a ConcurrentModifcationException. 

\emph{Storage:} in Hazelcast 2 the Queue/List/Set were build on top of the Map and by accessing the Map you could influence the map its behavior including storage. This isn't possible anymore in Hazelcast 3. The Queue now has its own QueueStore mechanism, but the List/Set have not. Perhaps this will be added in later versions.

\emph{Replication:} the List and Set can't be configured and will automatically have 1 synchronous backup and 1 asynchronous backups. Perhaps in the future this is going to be configurable.

\emph{Destruction:} IQueue/ISet/IList instances immediately are destroyed when they are empty, so they do not need to be destroyed explicitly. So when they are empty, they do not take up any space in Hazelcast. Listeners will remain registered, unless that collection is destroyed explicitly. Once an item is added to implicit destroyed collection, it will automatically be restored.

\emph{Not partitioned:} Queue/Set/List are not partitioned; so their size can't grow beyond the capacity of a single JVM. This is a big difference compared to Hazelcast 2.x where they were partitioned. On the background the List/Set are implemented as a collection in a MultiMap. This limitation certainly needs to be taken into consideration when designing a distributed system. One way to solve the problem is the use multiple collections,  rely on the map which is partitioned, or perhaps write the collection yourself using the new SPI functionality [todo: reference to SPI chapter]

\section{What is next?}
The api shown in these examples is only a subsection of what Hazelcast provides.[todo]