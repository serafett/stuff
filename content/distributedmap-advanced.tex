\chapter{Distributed Map Advanced}

\section{High availability}

By default all data that is written will automatically be written synchronously to another jvm. This prevents data from getting lost if a jvm crashes, because it will be available on another jvm. By customizing the Hazelcast configuration file:
\begin{verbatim}
<hazelcast> 
<map name="customers"> 
<backup-count>1</backup-count>
 	</map> 
</hazelcast>
\end{verbatim}

This configuration specifies that the customers map should have a single backup. This is also the default, so if you are fine with that, you do not need to specify it. But if you 

This configuration 
Consistency
todo explain default
Explain asynchronous
Persistence

If the partitions in a map are backed up by another node, no data will be lost if a node fails. But sometimes you need more. And sometimes you need to integrate with existing system e.g. databases, to store and retrieve information from. If you only need to load information into the system, you can implement the com.hazelcast.core.MapLoader interface and if you also need to store you need to implement the com.hazelcast.core.MapStore interface (which extends the MapLoader interface).

We are going to provide a very basic in memory version of the MapStore interface:

\begin{verbatim}
public class CustomerStore implements MapStore<String,Customer>{
   private final Map<String,Customer> customers = new HashMap<String,Customer>();
   public CustomerStore(){
      store(new Customer("Homer"));
      store(new Customer("Bart"));
      store(new Customer("Marge"));
   }
   private void store(Customer customer){
      customers.put(custer.getId(),customer);
   }
   public synchronized Customer load(String key){
      return customers.get(key);
   }
   public synchronized Map<String,Customer>	loadAll(Collection<String> keys){
      return new HashMap<String,Customer>(customers);
   }
   public synchronized void delete(String key){
      customers.remove(key);
   } 
   public synchronized void deleteAll(Collection<String> keys){
      for(String key: keys) customers.remove(key);
   } 
   public synchronized void store(String key, Customer value){
      customers.put(key, value);
   } 
   public synchronized void storeAll(Map<K,V> map){
      customers.putAll(map);
   }   
}
\end{verbatim}

And it can be configured like this:

\begin{verbatim}
<hazelcast>
    ...
    <map name="customers">
        ...
        <map-store enabled="true">
           <class-name>com.hazelcast.examples.CustomerStore</class-name>
           <write-delay-seconds>0</write-delay-seconds>
        </map-store>
    </map>
</hazelcast>
\end{verbatim}

The write-delay-seconds defaults to 0 and this means that if a change is made in the map, a write through to the CustomerStore is going to happen. Although this example doesn't use a database, but if one would be used, the database would immediately be updated if the map is updated. If the write-delay-seconds is higher than zero, the entry will be marked as dirty and at some point in time it will be written to the database, this is called a write behind.

\section{Indexes}

To speed up queries, just like in databases, Hazelcast indexes to be created on fields. In this case we could create a index on the name field. Using an index prevents from iterating over all possible values (in database terms this is called a full table scan), but directly jump to the interesting ones. There are 2 types of indexes:
Ordered: e.g. a numeric field
Unordered: e.g. a name field.
A single table can have multiple indexes. To retrieve the index field of an Object, first a getter will be tried and if that doesn't exist, direct field access will be used.

We can create an index in 2 ways:
programmatically
configuration
Programmatic configuration of the index.

An index can be added programmatically by calling the IMap.addIndex method like this:

\begin{verbatim}
class CustomerService{
    private final IMap<String,Customer> customerMap = Hazelcast.getMap("customers");

    public CustomerService(){
       customerMap.addIndex("name",true);
    }
\end{verbatim}

Adding the index should be done before an item is placed in the map. Sometimes by design adding an index to map may be impossible before any value is added. For example if a map has MapLoader that loads entries during map creation, then adding indexes to map becomes meaningless. To solve this problem, Hazelcast introduces defining IMap indexes in configuration.
Configuration of the index through the configuration file:

The indexes on the map can also be configured through the hazelcast configuration file. 

\begin{verbatim}
<hazelcast>
   ...
<map name="customers">
   ...
   <indexes>
      <index ordered="false">name</index>
      <index ordered="true">age</index>
   </indexes>
</map>
</hazelcast>
\end{verbatim}

Apart from solving the issue with programmatic index creation, other advantages of using the configuration file is that map configuration it isn't spread over the Java code and makes configuring and tuning the system a lot easier.

TODO: Give example of performance difference of using a map with and without index.

\section{Data locality}

In some cases you want data that logically belongs to each other, is stored on the same partition to have locality of reference (an important feature for performance). 

Imagine that a customer also can have orders, we could code it like this:

\begin{verbatim}
import java.io.Serializable;
import java.util.UUID;

public final class Order implements Serializable {
   private final String orderId = UUID.randomUUID().toString();
   private final String customerId;
   private final String articleId;
   private final int quantity;
   public Order(String customerId, String articleId, int quantity){
      this.customerId = customerId;
      this.articleId = articleId;
      this.quantity = quantity;
    }
    public String getOrderId(){return orderId;}
    public String getCustomerId(){return customerId;}
    public String getArticleId(){return articleId;}
    public int getQuantity(){return quantity;}
}

public class OrderService{
   private final Map<String,Order> orderMap = Hazelcast.getMap("orders");
   public void placeOrder(String customerId, String articleId, int count){
      Order order = new Order(customerId, articleId, count);
      orderMap.put(order.getOrderId(),order);
   }
}
\end{verbatim}

The problem is that the Orders are very likely to be stored on a different partition than the customers since the customer will 
be partitioned with the customer id, and the order with the order id. 

This can be solved by making use of the PartitionAware interface. If a key for the IMap implements this interface, instead 
of using the hashcode of the object to determine the correct partition, the PartitionAware.getPartitionKey() method will be 
called and the result of this method will be used to determine the right partition.

In our case we introduce an intermediate object: the OrderKey that implements this PartitionAware interface and returns the 
customerId as the partitionKey.

\begin{verbatim}
import com.hazelcast.core.PartitionAware;

import java.io.Serializable;

public final class OrderKey implements PartitionAware, Serializable {
   private final String orderId;
   private final String customerId;
   public OrderKey(String orderId, String customerId){
      this.orderId = orderId;
      this.customerId = customerId;
   }
   public Object getPartitionKey(){return customerId;}
   public int hashCode(){return orderId.hashCode();}
   public boolean equals(Object thatObject){
      if(thatObject == this)return true;
      if(!(thatObject instanceof OrderKey))return false;
      OrderKey that = (OrderKey)thatObject;
      return that.orderId.equals(this.orderId);
   }
}
\end{verbatim}

And we can integrate it in our code like this:

\begin{verbatim}
import com.hazelcast.core.Hazelcast;

import java.util.Map;

public class OrderService {
   private final Map<OrderKey, Order> orderMap = Hazelcast.getMap("orders");

   public String placeOrder(String customerId, String articleId, int quantity) {
      Order order = new Order(customerId, articleId, quantity);
      OrderKey key = new OrderKey(order.getOrderId(),customerId);
      orderMap.put(key,order);
      System.out.printf(
		"Order with id %s created: customer: %s, articleId %s, quantity %s\n",
         	order.getOrderId(),customerId,articleId,quantity);
      return order.getOrderId();
   }
}
\end{verbatim}

And we call it like this:

\begin{verbatim}
public class Main {
   public static void main(String[] args){
      CustomerService cs = new CustomerService();
      OrderService os = new OrderService();
      String customerId = cs.create("Homer");
      String orderId = ps.placeOrder(customerId,"123",1);
      PartitionService ps = Hazelcast.getPartitionService();
      Partition cp = ps.getPartition(customerId);
      Partition op = ps.getPartition(new OrderKey(orderId,customerId));
      System.out.printf("CustomerPartition: %s\n",cp.getPartitionId());
      System.out.printf("OrderPartition: %s\n",op.getPartitionId());
   }
}
\end{verbatim}

The Output would look something like this:

\begin{verbatim}
Customer Homer with id 9e556af1-6d63-4205-a70f-661ad7e9be72 and name Homer created
Order with id cb54f7ec-19f8-46b6-995a-a25b465c57fa created: customer: 9e556af1-6d63-4205-a70f-661ad7e9be72, articleId 123, quantity 1
CustomerPartition: 206
OrderPartition: 206
\end{verbatim}

As you can see, the partition where the Customer is stored, is the same as the partition where the Order of that same customer is stored. 

Being able to control what data is placed in the same partition, is a very powerful feature and needs to be taking into consideration from 
the beginning. Once this is done correctly, it will be a lot easier to write a high performance and scalable system. 

\section{Near Cache}

Till so far all our data is bound to a specific partition, e.g. the orders, the customer etc. But in some cases 
data needs to be available on all machines, an example of such data is reference data. Hazelcast luckily supports 
a feature called the near cache that makes data available on all partitions instead of a single one.

To explain the near cache, we are going to introduce the article domain object. We could define it like this:

\begin{verbatim}
public final class Article implements Serializable{
   private final String articleId = UUID.randomUUID().toString();
   private final String name;
   public Article(String name){this.name = name;}
   public String getArticleId(){return articleId;}
   public String getName(){return name;}
}
\end{verbatim}

If we want to verify that an article exist when an order is placed, we could do it like this:

\begin{verbatim}
public class OrderService{
   private final Map<String,Order> orderMap = Hazelcast.getMap("orders");
   private final Map<String,Article> articleMap = Hazelcast.getMap("articles");

   public void placeOrder(String customerId, String articleId){
      Article article = articleMap.get(articleId);
      if(article == null)throw new IllegalArgumentException();
      Order order = new Order(customerid, articleId);
      orderMap.put(order.getOrderId(),order);
   }
}
\end{verbatim}

Imagine that some articles, e.g. an IPad are very hot and will be ordered by many customer all the time. The problem is that because the IPad article object only lives at a single partition, that all other partitions need to make a potentially remote call to verify the existence of the IPad article. The consequence of doing remote calls is going to slow the system down (remote calls cause network traffic so prevent scalability and introduce latency).

Luckily Hazelcast provides another cool feature called the Near Cache. Items that are mostly read only, in this case an Article, will automatically be copied to all nodes that use it and not only to a single node that owns it. So if we have 5 nodes, and on all the 5 nodes the IPad article is ordered often, we are going to have 5 instances of the Ipad article because each node will have its own instance.

The Near Cache can be configured like this:
\begin{verbatim}
<hazelcast>
  ...
    <map name="articles">
      ...
      <near-cache>
        <time-to-live-seconds>0</time-to-live-seconds>
        <max-idle-seconds>60</max-idle-seconds>
        <eviction-policy>LRU</eviction-policy>
        <max-size>5000</max-size>
        <invalidate-on-change>true</invalidate-on-change>
      </near-cache>
    </map>
</hazelcast>
\end{verbatim}

todo: explain the different arguments
todo: give performance example with near cache enabled/disabled

\section{Multi Map}

In some cases you need to attach multiple values for a single key. Luckily Hazelcast provides out of the box functionality for that in the form of a MultiMap. The Hazelcast MultiMap documentation can be found here: http://www.hazelcast.com/javadoc/com/hazelcast/core/MultiMap.html
The MultiMap doesn't implement the java.util.Map interface since the signatures of the method are different. The MultiMap does have support for most of the functionality provided by the IMap (so locking, listeners etc). But it doesn't support indexing.

todo: good example with multi map; perhaps use orderline and drop order?

Creating a MultiMap

\begin{verbatim}
class Foo{
   private final MultiMap map = Hazelcast.getMultiMap("foo");
	
}
\end{verbatim}

Adding a value

\begin{verbatim}
public void add(String key, String value){
	map.put("key",value);
}
\end{verbatim}

Retrieving all values

\begin{verbatim}
	public Collection<String> getAll(String key){
		return map.get(key);
	}
\end{verbatim}

It is important to realize that this a copy of the values at some moment in time. Changes to this collection will not reflect as changes in the stored values. todo: is this collection readonly?

Removing items

\begin{verbatim}
   public boolean remove(String key, String value){
      return map.remove(key,value);
   }

   public Collection<String> removeAll(String key){
      return (Collection<String>)map.remove(key);
   }
\end{verbatim}

\section{Many Map}

todo: explanation of the Many Map

\section{What is next}
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi libero sem,
interdum eget varius vel, faucibus placerat purus. Sed vulputate diam sit amet
risus dapibus dignissim. Praesent lobortis eleifend augue. Cum sociis natoque
penatibus et magnis dis parturient montes, nascetur ridiculus mus. Morbi libero
turpis, viverra ac vulputate a, faucibus vel quam. Quisque interdum congue
lacus, in tempus nisl tincidunt at. Curabitur sed eros eu enim vehicula
fermentum quis nec justo. Vestibulum rutrum laoreet est, eget condimentum justo
feugiat at. Cras ac sem ac magna ornare tempor non nec nisl. Maecenas feugiat
fringilla nisl, vitae ullamcorper ante posuere a. Sed mollis lacinia interdum.
Vivamus vel urna metus. Nulla eget tellus sem. Praesent volutpat suscipit nulla,
nec dictum arcu iaculis id. Duis pharetra vestibulum sapien, quis pulvinar odio
pharetra id. Cras at erat velit, vel tincidunt elit. Curabitur vehicula leo eu
odio vulputate ac consequat nulla ultricies. Maecenas venenatis condimentum
urna ut ultrices. Aliquam blandit fermentum eros, ac lacinia sem scelerisque
at. Nullam vitae nisi at erat posuere cursus a non velit.