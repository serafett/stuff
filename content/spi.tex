\chapter{SPI}

One of the most exiting new features of Hazelcast 3 is the new SPI module (see the 'com.hazelcast.spi' package). The cool thing about this package is that it makes it possible to write first class distributed services/data-structures yourself. They pulled out this API into user space, but it also the core of all the Hazelcast functionality like the Map or the distributed executor relies on the same functionality. So with the SPI you can write your own data-structures if you are unhappy with the ones provides by Hazelcast. You also could write more complex services like an Actor library; I have build a POC actor library on top of Hazelcast where the actors automatically scale and are highly available. The only limiting factor is your imagination.

In this chapter we are going to build a distributed counter, so a counter that stored somewhere in the datagrid. The full sources can be found ...

\section{Phase 1}
In this section we are going to show you a very basic service that will be started when Hazelcast starts and will be shutdown when Hazelcast is shutdown. In itself not extremely interesting, but it is needed for the the more advanced sections.

\begin{lstlisting}[language=java]
import com.hazelcast.spi.*;
import java.util.Properties;
public class DistributedCounterService implements ManagedService {
    private NodeEngine nodeEngine;
    public void init(NodeEngine nodeEngine, Properties properties) {
        System.out.println("DistributedCounterService.init");
        this.nodeEngine = nodeEngine;
    }
    public void shutdown() {
        System.out.println("DistributedCounterService.shutdown");
    }
}
\end{lstlisting}

\begin{lstlisting}[language=xml]
<hazelcast>
    <services>
         <network>
            <join><multicast enabled="true"/> </join>
        </network>
        <service enabled="true">
            <name>DistributedCounterService</name>
            <class-name>DistributedCounterService</class-name>
         </service>
    </services>
</hazelcast>
\end{lstlisting}
If you need to set additional properties on the Service, a '<properties>' section can be added to the service. We also enabled multicast discovery since we'll rely on that later.

\begin{lstlisting}[language=java]
import com.hazelcast.core.Hazelcast;
public class Member {
    public static void main(String[] args) {
        Hazelcast.newHazelcastInstance();
    }
}
\end{lstlisting}
If we start it we'll see:
\begin{lstlisting}
DistributedCounterService.init
\end{lstlisting}

\section{Phase 2}
This example shows invoke operations on potentially a machine. The basis will be an Echo Service, that accepts a routing id and a message that needs to be echoed.

So lets start with the Echoer interface; it extends the 'DistributedObject' which provides name?/id/destroy
\begin{lstlisting}[language=java]
import com.hazelcast.core.DistributedObject;
public interface DistributedCounter extends DistributedObject {
    int inc(int amount);
}
\end{lstlisting}
The echo method takes 2 parameters: the routingId and the msg. The routingId is used to find the correct partition. 

The next step is the EchoService. Apart from implementing the 'ManagedService' interface, it now also implements the 'RemoteService' interface. Through this interface a client will be able to get a handle of an Echoer instance.
\begin{lstlisting}[language=java]
public class DistributedCounterService implements ManagedService, RemoteService {
    ...  
    public DistributedObject createDistributedObject(Object objectId) {
        return new DistributedCounterProxy(String.valueOf(objectId),nodeEngine);
    }
    public String getServiceName() {return "DistributedCounterProxy";}
    public DistributedObject createDistributedObjectForClient(Object objectId) {
        return null;
    }
    public void destroyDistributedObject(Object objectId) {}
}
\end{lstlisting}
[todo: destroyDistributedObject]
[todo: createDistributedObjectForClient]

\begin{lstlisting}[language=java]
import com.hazelcast.nio.*;
import com.hazelcast.spi.*;
import java.io.IOException;
import java.util.concurrent.*;
public class DistributedCounterProxy implements DistributedCounter {
    private final NodeEngine nodeEngine;
    private final String objectId;
    public DistributedCounterProxy(String objectId, NodeEngine nodeEngine) {
        this.nodeEngine = nodeEngine;
        this.objectId = objectId;
    }
    public Object getId() {return objectId;}
    public String getName() {return null;}
    public int inc(int amount) {
        IncOperation operation = new IncOperation(objectId, amount);
        int partitionId = nodeEngine.getPartitionService().getPartitionId(objectId);
        InvocationBuilder builder = nodeEngine.getOperationService()
                .createInvocationBuilder("DistributedCounterService", operation, partitionId);
        try {
            final Future<Integer> future = builder.build().invoke();
            return future.get();
        } catch (InterruptedException | ExecutionException e) {
            throw new RuntimeException(e);
        }
    }
    static class IncOperation extends AbstractOperation {
        private String objectId;
        private int amount,returnValue;
        public IncOperation(){}
        public IncOperation(String objectId, int amount) {
            this.amount = amount;
            this.objectId = objectId;
        }
        protected void writeInternal(ObjectDataOutput out) throws IOException {
            super.writeInternal(out);
            out.writeUTF(objectId);
            out.writeInt(amount);
        }
        protected void readInternal(ObjectDataInput in) throws IOException {
            super.readInternal(in);
            objectId = in.readUTF();
            amount = in.readInt();
        }
        public void run() throws Exception {
           System.out.println("Executing "+objectId+".inc() on: "+getNodeEngine().getThisAddress());            
           returnValue = 0;
        }
        public boolean returnsResponse() {return true;}
        public Object getResponse() {return returnValue;}
    }
    public void destroy() {}
}
\end{lstlisting}
todo: the operations always need to have a no arg constructor for deserialization purposes. You can also see that the right hazelcast partition to send the inc operation to is based on the object id. Of course you are free to route on any other field, or not route at all [todo: confirm that without the routing id, it will be a random machine]. Also a future is used as a handle to the operation completion. Currently I don't use any timeout, but you are free to add timouts. Instead of returning the value, you could expose the Future in the api, e.g. Future<Integer> inc(). In the example I do no deal correctly with the ExecutionException, it is best to get the cause and throw that. There is one thing you need to watch out for in that case, the stacktrace of that exception will represent the callstack of the thread executing the remote operation, not the callstack on the client side. An easy way to fix that is to prepend  the client side stacktrace in the stacktrace (the stacktrace is just an array of StackTraceElements)

Of course we also want to run the EchoService; the following example shows how it is run:
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
public class Member {
    public static void main(String[] args) {
        HazelcastInstance[] instances = new HazelcastInstance[2];
        for (int k = 0; k < instances.length; k++) 
            instances[k] = Hazelcast.newHazelcastInstance();
        DistributedCounter[] counters = new DistributedCounter[4];
        for (int k = 0; k < counters.length; k++) {
            DistributedCounter counter = (DistributedCounter) instances[0]
               .getDistributedObject("DistributedCounterService", "counter" + k);
            counters[k] = counter;
            System.out.println(counter.inc(1));
        }
       System.out.println("Finished");
    }
}
\end{lstlisting}

The output will show something like this:
\begin{lstlisting}
Executing counter0.inc() on: Address[192.168.1.101]:5702
0
Executing counter1.inc() on: Address[192.168.1.101]:5701
0
Executing counter2.inc() on: Address[192.168.1.101]:5701
0
Executing counter3.inc() on: Address[192.168.1.101]:5701
0
Finished
\end{lstlisting}
We can see that our counters are being stored in different members (check the different port numbers). We can also see that the increment doesn't do any real logic yet since the value remains 0.

\section{Phase 3}
In this section we are going to make use of real DistributedCounter; so some kind of data-structure that will hold an integer value (an AtomicInteger) and can be incremented. The first thing we do is for every partition we have, we are going to create a Container. And this contains will contain all AtomicIntegers for that given partition:
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import com.hazelcast.spi.*;
import java.util.Properties;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
public class DistributedCounterService implements ManagedService, RemoteService {
    private NodeEngine nodeEngine;
    DistributedMapContainer[] containers;
    public void init(NodeEngine nodeEngine, Properties properties) {
        this.nodeEngine = nodeEngine;
        containers = new Container[nodeEngine.getPartitionService().getPartitionCount()];
        for(int k=0;k<containers.length;k++) containers[k]=new Container();
    }
    public class Container{
        private final ConcurrentMap<String,AtomicInteger> counterMap = new ConcurrentHashMap<>();
        public int inc(String id,  int amount) {
            AtomicInteger counter = counterMap.get(id);
            if(counter == null){
                counter = new AtomicInteger();
                AtomicInteger found = counterMap.putIfAbsent(id, counter);
                counter = found == null ? counter : found;
            }
            return counter.addAndGet(amount);
        }
    }
\end{lstlisting}
As you can see the partitions are created in the init method. The Container also has an inc method, that looks up the AtomicInteger based on the id and increments it. Of course we need to connect the IncOperation.run method to the Container.inc method:
\begin{lstlisting}[language=java]
import com.hazelcast.nio.*;
import java.io.IOException;
import java.util.concurrent.ExecutionException;
public class DistributedCounterProxy implements DistributedCounter {
    ... 
    static class IncOperation extends AbstractOperation {
        public void run() throws Exception {
            System.out.println("Executing "+objectId+".inc() on: "+getNodeEngine().getThisAddress());
            DistributedCounterService service = getService();
            int partitionId = getNodeEngine().getPartitionService().getPartitionId(objectId);
            returnValue = service.containers[partitionId].inc(objectId, amount);
        }
        ...
    }
}
\end{lstlisting}
When we run the code, we'll see:
\begin{lstlisting}
1
2
\end{lstlisting}
This means that we now have a basic distributed counter up and running!

\section{Phase 4}
In our previous phase we managed to create real distributed counters. The problem is that if a node goes down, there will not be any backups because the values are not replicated to another machine. This means that the DistributedCounters are not highly available. In this phase we are going to add replication.

\section{Phase 4}
Migration

\section{What is next}