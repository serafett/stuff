\chapter{Hazelcast Clients}
Till so far the examples showed members that were full participants in the cluster; so they will known about others and they will take their share in the load. But in some cases you only want to connect to the cluster to read/write data or execute operations, but you don't want to have a member of the cluster; in other words you want to have a client.

We are going to implement a native and lite member client implementation in this chapter. Both are going to put a message on a queue and the message will be taken by the following full member:
\begin{lstlisting}[language=java]
public class FullMember {
    public static void main(String[] args)throws Exception{
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        BlockingQueue<String> queue = hzInstance.getQueue("queue");
        for(;;) System.out.println(queue.take());}}
\end{lstlisting}

With the native client one can connect to the cluster purely as a client and not have any of the responsibilities a normal cluster member has. When a Hazelcast operation is performed by a native client, it is forwarded to a cluster member where it will be processed. A native client only needs to have the hazelcast-client.jar on the classpath (+/- 150 kB depending on the version), the normal Hazelcast jar is not needed. Underneath you can see the native client example:
\begin{lstlisting}[language=java]
public class NativeClient {
    public static void main(String[] args) throws Exception {
        ClientConfig clientConfig = new ClientConfig().addAddress("127.0.0.1");
        HazelcastInstance client = HazelcastClient.newHazelcastClient(clientConfig);
        BlockingQueue<String> queue = client.getQueue("queue");
        queue.put("Hello");
        System.out.println("Message send by native member!");}}
\end{lstlisting}
The client HazelcastInstance is created based on the com.hazelcast.client.ClientConfig. This config is configured with 127.0.0.1 as address since the full member will be running on the same machine as the client.

First start the full member and then start the native client, and we can see that "Hello!" is printed by the full member. We'll also see that the native client never appears as member in the member listing.	
 
\emph{Failover} for the client can be realized by explicitly configuring multiple member addresses in the ClientConfig to increase the chance that one of these members will be up and running. Once the client has connected to the cluster, it will keep up to date with all the member addresses of the cluster and not just the provided members.

\emph{LoadBalancing}. If the client sees that a request needs to be send to a particular member or partition, it will try have the request executed directly at that member, otherwise the client will do a round robin over the full list of the cluster members, not just the list of the provided members in the ClientConfig.  Currently it isn't possible to inject some kind of load balancing strategy so you can load balance on memory usage, cpu load etc but perhaps this will be added in the future. 

There can be hundreds, even thousands of clients connected to the cluster. But by default there are 40 threads on each member that will handle all the client request. This is configurable using the hazelcast.executor.client.thread.count property

The clients are thread-safe so you don't need to pool them.

In the native client example, we did a minimal configuration of the ClientConfig and relied on defaults, but there is a lot that can be configured:
\begin{enumerate}
\item addresses: the known addresses of the cluster. They don't need to include all addresses, only enough to make sure that some will always be online.
\item connection timeout: the amount of time in milliseconds the native client waits for one of the members, configured with the addresses property, of the cluster to come online before giving up. Defaults to 5 minutes.
\item credentials: can be used to configure username/password to connect to the cluster. See UsernamePasswordCredentials.
\item group config: configures the group name and the password to access the group.
\item connection timeout defaults to 30000
\item initial connection attempt limit:the  number of connection attempts the client makes the initial connection to the cluster. Defaults to 1.
\item reconnect attempt limit: the number of reconnection attempts the client makes when a connection fails. Defaults to 1.
\item reconnect timeout: [todo]. Defaults to 5000 ms.
\item shuffle:[TODO]. Defaults to false.
\item update automatic:[TODO] Defaults to true.
\item socketInterceptor
\item listeners: EventListener
\end{enumerate}

\section{What happened to the lite member?}
If you have been using Hazelcast 2.x you might remember the lite member. The lite member participates as a cluster member, but isn't going to be responsible for hosting any partitions. The advantage of a lite member compared to a native client was that the latter didn't know about routing requests to the correct members and therefor was less performant. But with Hazelcast 3.x this limitation was removed and therefor the lite member didn't serve a purpose anymore and was removed.

\section{What is next}
In this short chapter we explained a few different ways to connect to a Hazelcast cluster using a client. But there are more client solutions available: like the C\# client (Hazelcast Enterprise Edition), the Memcache Client and the Rest Client. For more information check the Client chapter of the Hazelcast reference manual.