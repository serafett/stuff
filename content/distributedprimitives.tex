\chapter{Distributed Primitives}

If you have programmed in Java you have probably worked with concurrency primitives like the synchronized statement (the intrinsic lock) or perhaps even the new concurrency library that was introduced in Java 5 under java.util.concurrent like the Executor, Lock and AtomicReference. And with every new release of Java all kinds of new functionality is added like the Fork/Join framework in Java 7.

This concurrency functionality is useful if you want to write a Java application that use multiple threads. The focus of this functionality however is to provide concurrency abstractions to be used in a single jvm, although you can always connect multiple JVM's together either using raw sockets or some kind of more higher level remoting library (RMI, Servlets etc)

Hazelcast provides direct support for synchronization primitives that are distributed. The advantage of using distributed data-structures is:
\begin{enumerate}
\item failover; so if one machine fails, the system will still be working
\item scalability; just add more machines and you will get more capacity. Although this doesn't mean that your system will automatically become better scalable when you introduce Hazelcast 
\end{enumerate}

In this chapter the following distributed primitives will be explained:
\begin{enumerate}
\item AtomicNumber
\item Lock
\item ISemaphore
\item ICountdownLatch
\item IdGenerator
\end{enumerate}

\section{AtomicNumber}

The AtomicNumber is the distributed version of the java.util.concurrent.atomic.AtomicLong. The main reason I'm using the AtomicNumber for is for are counters. 

Below is a small example:
\begin{lstlisting}[language=java]
public class AtomicNumberMain{
    public static void main(String[] args){
        AtomicNumber counter = Hazelcast.getAtomicNumber("counter");
        int count = 1000 * 1000;
        for(int k=0;k<count;k++){
            counter.incrementAndGet();
        }
        System.out.printf("Count is %s\n",counter.get());
    }
}
\end{lstlisting}
In this case the counter is incremented 1000*1000 times and if you run this application in parallel, then the total count should be equal to 1000*1000 times the number of applications you have started.

The AtomicNumber exposes most of the operations the AtomicLong provides like:
\begin{enumerate}
\item get
\item set
\item getAndSet
\item compareAndSet
\item incrementAndGet
\end{enumerate}
so if you have used the AtomicLong before, working with the AtomicNumber should feel similar.

With the AtomicNumbers can be used in lock free algorithms, although you need to take care that uncontrolled repeating can lead to live-locking; the system is appears to do something, but in reality it is only burning cpu cycles. In case of a distributed version the system will also be consuming network resources. 

If the counter is going to be a contention point in your system, you can either create a stripe (an array) of counters and pick one to increment. With n counters in place, you should have n times more scalability. Another option is to store increments locally and only once and a while increment the shared counter. The downside of this approach is that you could loose counts if a node goes down for example. Another downside is that the newest count is not always immediately visible. 

There currently is only support for the long. But you can always use this to simulate
\begin{enumerate}
\item boolean: 0 for true and 1 for false.
\item double: a 64 bit double can be encoded into 64 bits, which can be stored in a long 
      which is also 64 bits.
\end{enumerate}


\section{Distributed Lock}

The Hazelcast ILock (which extends the java.util.concurrent.locks.Lock) is perhaps to most basic concurrency primitive. As you know a Lock makes it possible that only a single thread is able to get access to a critical section of code; if multiple threads at the same moment would access that critical section concurrently, you would get race problems. 

With the Hazelcast ILock you can not only create a critical section within a single JVM, you can do it within a cluster of JVM's; so if one node in that cluster acquired that lock, other nodes in the cluster will not; they will need to wait till the lock is released.

In the following example we have 2 atomic numbers and they will be incremented without using a lock.
\begin{lstlisting}[language=java]
import com.hazelcast.core.AtomicNumber;
import com.hazelcast.core.Hazelcast;

public class NoLockMain {
    public static void main(String[] args) throws InterruptedException {
        AtomicNumber number1 = Hazelcast.getAtomicNumber("number1");
        AtomicNumber number2 = Hazelcast.getAtomicNumber("number2");
        System.out.println("Started");
        for (int k = 0; k < 1000000; k++) {
            if (k % 10000 == 0) System.out.println("At: " + k);
            if (k % 2 == 0) {
                long n1 = number1.get();
                Thread.sleep(100);
                long n2 = number2.get();
                if (n1 - n2 != 0) System.out.println("Difference detected!");
            } else {
                number1.incrementAndGet();
                number2.incrementAndGet();
            }
        }
        System.out.println("Finished");
    }
}
\end{lstlisting}

After we the application multiple times we are going to see the following in the console:
\begin{verbatim}
At 0
Difference detected!
Difference detected!
...
\end{verbatim}	

The reason is that the writing and the reading of the 2 numbers is not an atomic operation. To make reading or writing to both the numbers atomic, we can make use of the Hazelcast distributed lock:

\begin{lstlisting}[language=java]
import com.hazelcast.core.AtomicNumber;
import com.hazelcast.core.Hazelcast;
import com.hazelcast.core.ILock;

public class LockMain {
    public static void main(String[] args) throws InterruptedException {
        AtomicNumber number1 = Hazelcast.getAtomicNumber("number1");
        AtomicNumber number2 = Hazelcast.getAtomicNumber("number2");
        ILock lock = Hazelcast.getLock("lock");
        System.out.println("Started");
        for (int k = 0; k < 10000; k++) {
            if (k % 100 == 0) System.out.println("at: " + k);
            lock.lock();
            try {
                if (k % 2 == 0) {
                    long n1 = number1.get();
                    Thread.sleep(10);
                    long n2 = number2.get();
                    if (n1 - n2 != 0) System.out.println("Difference detected!");
                } else {
                    number1.incrementAndGet();
                    number2.incrementAndGet();
                }
            } finally {
                lock.unlock();
            }
        }
        System.out.println("Finished");
    }
}
\end{lstlisting}

When this code is executed; you will not see "Difference detected!" anymore. This is because the lock provides a critical section around writing and reading of the numbers. 

With the java.util.concurrent.locks.Lock it also is possible to create a java.util.concurrent.locks.Condition object to wait for a certain condition to happen; e.g. a custom made queue just received an element. Unfortunately the Condition functionality is not supported by Hazelcast at the moment.

TODO: Hazelcast lock is reentrant, so you can acquire it multiple times in a single thread without causing a deadlock, and of course you need to release it as many times as you have acquired it, to make it available to other threads.

Important: when a node has acquired a lock and this node goes down, then that lock will automatically be released. This prevents threads that are waiting for a lock to wait indefinitely and this is important for failover to work in a distributed system. The downside however is that if a node that acquired the lock and started making changes, goes down, that other nodes could start to see partial changes. In these cases either the system could do some self repair or else a transaction potentially can solve the problem.

\section{ISemaphore}

The ISemaphore in Hazelcast is distributed version of the java.util.concurrent.Semaphore implementation. a counting semaphore; it can be seen as a structure with a limit number of permits. When a permit needs to be obtained, a few things can happen:
\begin{enumerate}
\item a permit is available; the number of permits in the semaphore is decreased by one and the calling thread returns.
\item no permit is available; the calling thread will block until a permit comes available, a timeout happens, the thread is interrupted or when the semaphore is destroyed a InstanceDestroyedException will be thrown.
\end{enumerate}

A semaphore that is initialized with the value 1, will have similar behavior as a lock, but with the big difference that with a semaphore a different thread is allowed to release the permit than the thread that acquired the permit.

\begin{lstlisting}[language=java]
public class SemaphoreMain{
    public static void main(String[] args)throws Exception{
        SemaphoreConfig config = new SemaphoreConfig()
            .setName("semaphore")
            .setInitialPermits(2);
        //todo: how to create a semaphore based on some config
        ISemaphore semaphore = Hazelcast.getSemaphore("semaphore");
        AtomicNumber counter = Hazelcast.getAtomicNumber("counter");
        for(int k=0;k<1000000;k++){
            semaphore.acquire();
            try{
                Thread.sleep(1000);
            }finally{
                semaphore.release();
            }
        }
    }
}
\end{lstlisting}

TODO: Explain attach

\section{ICountDownLatch}
The CountDownLatch was introduced in Java 1.5 and is a synchronization aid that makes it possible for threads to wait until a set of operations being performed in another thread  complete. Very simplistically; a CountDownLatch could be seen as a gate containing a counter; behind this gate threads can wait till the counter reaches zero. In my experience CountDownLatches often are used when you have some kind of processing operation, and you one or more threads that wait till this operation is completed so they can do their logic.

In Hazelcast there also is a CountDownLatch; the org.hazelcast.core.ICountDownLatch. The following example is made up by 2 parts; 1 part is the 'Leader'. It will create a latch and do a 'countdown' to release it:

And we start a single leader, 
\begin{lstlisting}[language=java]
public class Leader{
    public static void main(String[] args)throws Exception{
        HazelcastInstance hazelcastInstance = Hazelcast.getDefaultInstance();
        ICountDownLatch latch = hazelcastInstance.getCountDownLatch("countDownLatch");
        
        System.out.println("Starting");
        //we init the latch with 1, since we only need to complete a single step.
        latch.setCount(1); 
        //do some sleeping to simulate doing something    
        Thread.sleep(5000);
        //now we do a countdown which opens the latch and all waiting
        //followers are notified.
        latch.countDown();
        System.out.println("Leader finished");
        //we need to clean up the latch
        latch.destroy();
    }
}
\end{lstlisting}

TODO: What happens when the latch is destroyed before all the followers are notitifed?

And we also need followers; so Java applications that are going to wait for the latch to notify them.

\begin{lstlisting}[language=java]
public class Follower{
    public static void main(String[] args)throws Exception{
        ICountDownLatch latch = Hazelcast.getCountDownLatch("countDownLatch");
        System.out.println("Waiting");
        latch.await();
        System.out.println("Complete!");
    }
}
\end{lstlisting}
We can spawn as many of these waiters as you want, and all will be displaying.

\begin{verbatim}
Waiting
\end{verbatim}

Once the leader counts down to zero, all followers will be notified and show the following output:

\begin{verbatim}
Waiting
Complete!
\end{verbatim}

This example show a CountdownSemaphore with only a single 'step'. But if the process has n steps, the countdownlatch can be initialized with n. In the following example a process that is made up of 2 steps is shown.

\begin{lstlisting}[language=java]
public class MultiStepLeader{
    public static void main(String[] args)throws Exception{
        ICountDownLatch latch = Hazelcast.getCountDownLatch("countDownLatch");
        latch.setCount(2);

        Thread.sleep(60000); 
        latch.countDown();
        System.out.println("Leader completed first step");
        
        Thread.sleep(60000); 
        latch.countDown();
        System.out.println("Leader completed both steps");
        latch.destroy();
    }
}
\end{lstlisting}

Although the ICountdownLatch is a very useful synchronization aid, it probably isn't one you will use on a daily basis.

In practice you will probably not have all the countdown latches needed created up front. A way to deal with this is to let the 'Leader' create a ICountDownLatch when it starts with its steps, and send the id of this ICountdownLatch to all the followers. The followers can then retrieve the CountdownLatch by calling Hazelcast.getCountdownLatch(..).

Important: unlike Java's implementation, Hazelcast's ICountDownLatch count can be re-set after a countdown has finished but not during an active count. This allows the same proxy instance to be reused.

-- TODO: Text is copied.
The Hazelcast member that successfully invokes setCount(int) becomes the owner of the countdown and is responsible for staying connected to the cluster until the count reaches zero. If the owner  becomes disconnected prior to count reaching zero all awaiting threads will be notified. This provides a safety mechanism in the distributed environment.

\section{IdGenerator}

In the previous section we introduced the AtomicNumber and one of the things it can be used for is to generated unique id's within a cluster. Although it will work, it probably isn't the most scalable solution since all member will content on incrementing the value. If you are only interested in id's and not in the order the id's are generated (or even when elements are skipped) you can have a look at the IdGenerator.

\begin{lstlisting}[language=java]
public class IdGeneratorMain{
    public static void main(String[] args){
        IdGenerator idGenerator = Hazelcast.getIdGenerator("idGenerator");
        int count = 1000 * 1000;
        for(int k=0;k<100;k++){
            long id = idGenerator.newId();
            System.out.printn("Id : %s\n",id);
        }
    }
}
\end{lstlisting}

The way the org.hazelcast.core.IdGenerator works is that each node claims a segment of id's to generate, e.g. 0..999999. This is done behind the scenes by incrementing a shared AtomicNumber. After it has claimed its segment, it can increment a local counter (so there is no network traffic). Only when the id's in its segments are used, then a new segment needs to be claimed and this is done by increasing the shared AtomicNumber.

This means that node's can generate id's much quicker (local increment vs a distributed one). And it will also scale a lot better because of reduced contention; instead of incrementing that AtomicNumber on every new id, only when all the id's in the segment are used, the AtomicNumber will be incremented.

Of course there are some downsides you need to be aware of:
\begin{enumerate}
\item the generated id's probably will be out of order
\item if a node goes down without using its range, there might be gaps.
\end{enumerate}
But for id generation, these limitations in most cases are not an issue.

Apart from the IdGenerator, there are other options for creating cluster wide unique id's. One of them is the java.util.UUID, although it will take up more space than a long. 

Important: If the cluster restarts then id generation will start from 0.

\section{What is next?}
In this chapter we went over the various synchronization primitives that are directly exposes by Hazelcast. You can always build higher synchronization primitives on top of these lower ones.

TODO: Deadlocks, Livelocks, starvation etc. If you know how a hammer and a saw work, it doesn't mean that you immediately can build a house with it.
