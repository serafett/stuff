\chapter{Custom Serialization}
Till so far all our examples have relied on standard Java serialization by letting the objects we store in Hazelcast, implement the java.io.Serializable interface. This mechanism is very generic and very easy to use, but it comes at a price:
\begin{enumerate}
\item lack of control on how the fields are serialized/deserialized.
\item suboptimal performance due to streaming class descriptors, versions, keeping track of seen objects to deal with cycles etc. This causes additional cpu load and suboptimal size of serialized data.
\end{enumerate}
That is why Hazelcast introduced a custom serialization mechanism based on the com.hazelcast.nio.DataSerializable interface. 

Serialization in Hazelcast works like this: when an object is placed in Hazelcast (e.g. in a map or queue), Hazelcast first checks if it is an instance of String, Long, Integer, byte[], ByteBuffer, Date etc, since serialization for these types can be optimized. If that fails, it checks if it is an instance of DataSerializable and if that fails it will fall back on Java serialization (or fails because the class isn't Serializable). 

To show how DataSerializable works, check the following example where a Person class is serialized:
\begin{lstlisting}[language=java]
import com.hazelcast.core.*;
import com.hazelcast.nio.DataSerializable;
import java.io.*;
import java.util.Map;
public class SerializationMember {
    public static void main(String[] args) {
        HazelcastInstance hzInstance = Hazelcast.newHazelcastInstance();
        Map<String, Person> map = hzInstance.getMap("map");
        map.put("Peter", new Person("Peter", 36));
        Person p = map.get("Peter");
        System.out.println(p);
    }
    public static class Person implements DataSerializable {
        private String name;
        private int age;
        private Person(){}
        public Person(String name, int age) {
            this.name = name;
            this.age = age;
        }
        public void writeData(DataOutput out) throws IOException {
            out.writeUTF(name);
            out.writeInt(age);
        }
        public void readData(DataInput in) throws IOException {
            this.name = in.readUTF();
            this.age = in.readInt();
        }
        public String toString() {
            return String.format("Person(name=%s,age=%s)",name,age);
        }
    }
}
\end{lstlisting}
As you can see the writing of the Person fields is done in the same order as reading. If you do it in a different order you will be running into problems. Another thing you can see is the no-arg Person constructor. This constructor is mandatory, failing to provide one will result in an IOException. Because of this constructor, which is allowed to be private, it could be that you need to relax your final field requirements.

If an object that implements DataSerializable, has a field that also is DataSerializable, the write and read operations need to be forwarded to that object. For example if we would add a DataSerializable address field to Person, the write and read operations of Person would look like this:
\begin{lstlisting}[language=java]
    public void writeData(DataOutput out) throws IOException {
        out.writeUTF(name);
        out.writeInt(age);
        address.writeData(out);
    }
    public void readData(DataInput in) throws IOException {
        name = in.readUTF();
        age = in.readInt();
        address = new Address();
        address.readData(in);
    }
\end{lstlisting}
One thing to look out for however are cycles between objects because it can lead to a stack overflow. Standard Java serialization protects against this, but since manual traversal is done in DataSerializable objects, out of the box there is no protection. If this becomes an issue, you could store a map in a ThreadLocal that can be used to check for cycles.

With the standard Java serialization mechanism there is a build in mechanism for class versioning. With the DataSerializable this isn't provided out of the box, but it is very easy to add. You can include a version field in the class that is written when the class is serialized. And when the class is deserialized, the version can be restored and one could even decide to read data in different ways based on the found version to ensure being able to read older serialized classes.

\section{Externalizable vs DataSerializable}
The java.io.Externalizable can also be used for serialization/deserialization since it extends Serializable. So when Hazelcast defaults to the standard Java serialization mechanism, the Externalizable mechanism works without a problem. Although Externalizable provides more control compared to Serializable, it still suffers from some overhead compared to a DataSerializable. So use it with care.

\section{serialVersionUID} 
When you create java.io.Serializable objects, make sure that they get a serialVersionUID. This prevents the JVM from calculating one on the fly and can lead to all kinds of class compatibility issues. In the examples I didn't add them to save space, but for production code there is no excuse.

\section{Good to know}

\emph{Caution} DataSerializable doesn't deal with nested serialization; so while you are serializing or deserializing a class, you should not call an operation on Hazelcast that leads to new DataSerializable serialize/deserialization calls,  doing so leads to a StackOverflowError. A solution to this problem is to execute the operation on a different thread. 

\emph{Caution} When an DataSerializable object x is wrapped in a normal Serializable object y and y is serialized, then will be serialized using Serializable as well. This works because the DataSerializable interface extends Serializable so therefor each object that is DataSerializable is Serializable by default.

\emph{The DataSerializable} also makes it possible to delegate to completely different serialization mechanisms like Protobuf, JSON etc.

\section{What is next}

[todo: pluggable serialization in Hazelcast 3.0]